{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import timm.optim.optim_factory as optim_factory\n",
    "from pathlib import Path\n",
    "from loss.loss import WeightedMSE\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "except:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import timm\n",
    "\n",
    "assert timm.__version__ == \"0.3.2\" # version check\n",
    "from timm.models.layers import trunc_normal_\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "\n",
    "import util_mamba.lr_decay as lrd\n",
    "import util_mamba.misc as misc\n",
    "from util_mamba.datasets import build_dataset\n",
    "from util_mamba.pos_embed import interpolate_pos_embed\n",
    "from util_mamba.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "from data_provider_labeled import Train as Trainset\n",
    "import yaml\n",
    "from attrdict import AttrDict\n",
    "from utils.show import show_one\n",
    "from utils.shift_channels import shift_func\n",
    "from segmamba import SegMamba\n",
    "\n",
    "from engine_finetune import train_one_epoch, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    cfg_file = 'seg_3d_cremiC_data100'\n",
    "    with open('/data/ydchen/VLP/wafer4/config/' + cfg_file + '.yaml', 'r') as f:\n",
    "        cfg = AttrDict(yaml.safe_load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Trainset(cfg, [16,256,256])\n",
    "dataloader = torch.utils.data.DataLoader(dataset_train, batch_size=1, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegMamba(in_chans=1, out_chans=3)\n",
    "model.load_state_dict(torch.load('//h3cstore_ns/EM_pretrain/mamba_seg_EM/EM_CREMIC_without_pre/checkpoint-399.pth')['model'])\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data,affi,weight_map) in enumerate(dataloader):\n",
    "    print(data.shape)\n",
    "    print(affi.shape)\n",
    "    print(weight_map.shape)\n",
    "    data = data.to(device)\n",
    "    affi = affi.to(device)\n",
    "    weight_map = weight_map.to(device)\n",
    "    output = model(data)\n",
    "    print(output.shape)\n",
    "    # show_one(data[0,0].cpu().numpy(), affi[0].cpu().numpy(), output[0].cpu().numpy(), weight_map[0].cpu().numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.max(),data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "affi_show = affi[0,:,10].cpu().numpy().transpose(1,2,0)\n",
    "out_show = output[0,:,10].detach().cpu().numpy().transpose(1,2,0)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(affi_show)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(out_show)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding window infer\n",
    "from monai.inferers import sliding_window_inference\n",
    "data, label, gt_aff = dataset_train.valid_provide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "data = torch.tensor(data)\n",
    "data = data.unsqueeze(0).unsqueeze(0).to(device)\n",
    "data = data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3')\n",
    "model = model.to(device)\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred_out = sliding_window_inference(data, (16,256,256), 12, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_out.shape, gt_aff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(pred_out[0,:,15].cpu().numpy().transpose(1,2,0))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(gt_aff[:,15].transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_fragments_3d(pred):\n",
    "    d,m,n = pred.shape\n",
    "    ids = np.unique(pred)\n",
    "    size = len(ids)\n",
    "    print(\"the neurons number of pred is %d\" % size)\n",
    "    color_pred = np.zeros([d, m, n, 3])\n",
    "    idx = np.searchsorted(ids, pred)\n",
    "    for i in range(3):\n",
    "        color_val = np.random.randint(0, 255, ids.shape)\n",
    "        if ids[0] == 0:\n",
    "            color_val[0] = 0\n",
    "        color_pred[:,:,:,i] = color_val[idx]\n",
    "    color_pred = color_pred\n",
    "    return color_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_color = draw_fragments_3d(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_color.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_aff1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "gt_aff1 = gt_aff[:,0]\n",
    "gt_aff_img = Image.fromarray((gt_aff1*255).astype(np.uint8).transpose(1,2,0))\n",
    "gt_aff_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.cpu().numpy()\n",
    "data1 = data1.squeeze()*255\n",
    "data_img = Image.fromarray(data1[0].astype(np.uint8))\n",
    "data_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "label_img = Image.fromarray(label_color[0].astype(np.uint8))\n",
    "label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_out\n",
    "pred_out.shape\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fragment import watershed, randomlabel\n",
    "pred_out = pred_out.squeeze(0)\n",
    "pred_out = pred_out.cpu().numpy()\n",
    "fragments = watershed(pred_out, 'maxima_distance')\n",
    "import waterz\n",
    "sf = 'OneMinus<HistogramQuantileAffinity<RegionGraphType, 50, ScoreValue, 256>>'\n",
    "seg_waterz = list(waterz.agglomerate(pred_out, [0.50],\n",
    "            fragments=fragments,\n",
    "            scoring_function=sf,\n",
    "            discretize_queue=256))[0]\n",
    "from skimage.metrics import adapted_rand_error as adapted_rand_ref\n",
    "from skimage.metrics import variation_of_information as voi_ref\n",
    "arand_waterz = adapted_rand_ref(label, seg_waterz, ignore_labels=(0))[0]\n",
    "voi_split, voi_merge = voi_ref(label, seg_waterz)\n",
    "voi_sum_waterz = voi_split + voi_merge\n",
    "print(f\"ARAND: {arand_waterz}, VOI: {voi_sum_waterz}, VOI_MERGE: {voi_merge}, VOI_SPLIT: {voi_split}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pred_out)\n",
    "type(label)\n",
    "pred_out.shape\n",
    "# label.shape\n",
    "seg_waterz.shape\n",
    "np.savez('pred_out.npz', pred_out)\n",
    "np.savez('label.npz', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fragment import watershed, randomlabel\n",
    "import numpy as np\n",
    "pred_out_npz = np.load('pred_out.npz')\n",
    "label_npz = np.load('label.npz')\n",
    "pred_out = pred_out_npz['arr_0']\n",
    "label = label_npz['arr_0']\n",
    "pred_out = norm01(pred_out)\n",
    "fragments = watershed(pred_out, 'maxima_distance')\n",
    "import waterz\n",
    "sf = 'OneMinus<HistogramQuantileAffinity<RegionGraphType, 50, ScoreValue, 256>>'\n",
    "seg_waterz = list(waterz.agglomerate(pred_out, [0.50],\n",
    "            fragments=fragments,\n",
    "            scoring_function=sf,\n",
    "            discretize_queue=256))[0]\n",
    "from skimage.metrics import adapted_rand_error as adapted_rand_ref\n",
    "from skimage.metrics import variation_of_information as voi_ref\n",
    "arand_waterz = adapted_rand_ref(label, seg_waterz, ignore_labels=(0))[0]\n",
    "voi_split, voi_merge = voi_ref(label, seg_waterz)\n",
    "voi_sum_waterz = voi_split + voi_merge\n",
    "print(f\"ARAND: {arand_waterz}, VOI: {voi_sum_waterz}, VOI_MERGE: {voi_merge}, VOI_SPLIT: {voi_split}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm01(x, mode=1):\n",
    "    if mode==0:\n",
    "        return (x.max()-x) / (x.max() - x.min())\n",
    "    elif mode == 1:\n",
    "        x = np.clip(x, a_min=0,a_max=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "pred_out_npz = np.load('pred_out.npz')\n",
    "pred_out = pred_out_npz['arr_0']\n",
    "pred_out = norm01(pred_out)\n",
    "print(pred_out.shape)\n",
    "pred_out1 = pred_out[:,0]\n",
    "pred_out1_img = Image.fromarray((pred_out1*255).astype(np.uint8).transpose(1,2,0))\n",
    "pred_out1_img.show()\n",
    "pred_out.min(),pred_out.max()\n",
    "\n",
    "# print(pred_out.shape)\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(pred_out[0,:,15])\n",
    "\n",
    "# gt_aff1 = gt_aff[:,0]\n",
    "# gt_aff_img = Image.fromarray((gt_aff1*255).astype(np.uint8).transpose(1,2,0))\n",
    "# gt_aff_img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "pred_out_npz = np.load('pred_out.npz')\n",
    "pred_out = pred_out_npz['arr_0']\n",
    "print(pred_out.shape)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(pred_out[:,0].transpose(1,2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "seg_waterz_color = draw_fragments_3d(seg_waterz)\n",
    "seg_waterz_img = Image.fromarray(seg_waterz_color[0].astype(np.uint8))\n",
    "seg_waterz_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
